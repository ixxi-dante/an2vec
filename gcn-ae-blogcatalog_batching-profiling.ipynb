{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph-convolutional auto-encoder: BlogCatalog / Batching profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import cProfile\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import sklearn.preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import networkx as nx\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from progressbar import ProgressBar\n",
    "from IPython.display import SVG, HTML, display\n",
    "\n",
    "from nw2vec import ae\n",
    "from nw2vec import utils\n",
    "from nw2vec import codecs\n",
    "from nw2vec import layers\n",
    "from nw2vec import viz\n",
    "from nw2vec import batching\n",
    "from nw2vec import graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Jacob is using GPU #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the full list of nodes and groups ###\n",
    "\n",
    "crop = None\n",
    "\n",
    "# nodes\n",
    "nodes = []\n",
    "with open('data/BlogCatalog-dataset/data/nodes.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    nodes = [int(row[0]) for row in reader]\n",
    "if crop is not None:\n",
    "    nodes = nodes[:crop]\n",
    "assert len(nodes) == len(set(nodes))\n",
    "nodes = set(nodes)\n",
    "\n",
    "# groups\n",
    "groups = []\n",
    "with open('data/BlogCatalog-dataset/data/groups.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    groups = [int(row[0]) for row in reader]\n",
    "assert len(groups) == len(set(groups))\n",
    "groups = set(groups)\n",
    "\n",
    "\n",
    "### Generate graph from edges and node data ###\n",
    "\n",
    "# Read edges.csv and make a network out of it\n",
    "edges = defaultdict(list)\n",
    "with open('data/BlogCatalog-dataset/data/edges.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        if crop is not None:\n",
    "            if int(row[0]) in nodes and int(row[1]) in nodes:\n",
    "                edges[int(row[0])].append(int(row[1]))\n",
    "        else:\n",
    "            edges[int(row[0])].append(int(row[1]))\n",
    "\n",
    "g = nx.from_dict_of_lists(edges, create_using=nx.Graph())\n",
    "if crop is not None:\n",
    "    g.add_nodes_from(nodes)\n",
    "\n",
    "# Read group-edges.csv and add that info to each node\n",
    "group_edges = defaultdict(list)\n",
    "with open('data/BlogCatalog-dataset/data/group-edges.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        if crop is not None:\n",
    "            if int(row[0]) in nodes:\n",
    "                group_edges[int(row[0])].append(int(row[1]))\n",
    "        else:\n",
    "            group_edges[int(row[0])].append(int(row[1]))\n",
    "\n",
    "for node, data in g.nodes.items():\n",
    "    data['groups'] = group_edges[node]\n",
    "\n",
    "\n",
    "### Sanity checks ###\n",
    "assert set(g.nodes) == nodes\n",
    "#CROP\n",
    "if crop is None:\n",
    "    assert set().union(*[groups for _, groups in g.nodes(data='groups')]) == groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set node labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros((len(nodes), len(groups)))\n",
    "nodes_offset = min(nodes)\n",
    "groups_offset = min(groups)\n",
    "for n, data in g.nodes.items():\n",
    "    labels[n - nodes_offset, np.array(data['groups']) - groups_offset] = 1\n",
    "#labels += np.random.normal(scale=.2, size=labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE Parameters\n",
    "n_nodes = len(nodes)\n",
    "adj = nx.adjacency_matrix(g).astype(np.float32)\n",
    "\n",
    "n_ξ_samples = 5\n",
    "dim_data, dim_l1, dim_ξ = len(groups), 10, 2\n",
    "dims = (dim_data, dim_l1, dim_ξ)\n",
    "use_bias = False\n",
    "\n",
    "# Actual VAE\n",
    "q_model, q_codecs = ae.build_q(dims, use_bias=use_bias)\n",
    "p_builder = ae.build_p_builder(dims, use_bias=use_bias)\n",
    "vae, vae_codecs = ae.build_vae(\n",
    "    (q_model, q_codecs), p_builder,\n",
    "    n_ξ_samples,\n",
    "    [\n",
    "        1.0,  # q loss\n",
    "        1.0,  # p adj loss\n",
    "        1.0,  # p v loss\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = utils.scale_center(labels)\n",
    "\n",
    "def target_func(batch_adj, required_nodes, final_nodes):\n",
    "    return [\n",
    "        np.zeros(1), # ignored\n",
    "        utils.expand_dims_tile(utils.expand_dims_tile(batch_adj + np.eye(batch_adj.shape[0]), 0, n_ξ_samples), 0, 1),\n",
    "        utils.expand_dims_tile(features[final_nodes], 1, n_ξ_samples),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before training\n",
    "\n",
    "$\\xi$ averages and distributions for each community, real and predicted adjacency matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_ξ_distribution(g, q_model, adj, labels, batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 4))\n",
    "#\n",
    "#im1 = ax1.imshow(nadj)\n",
    "#ax1.set_title('Real adjacency matrix')\n",
    "#plt.colorbar(im1, ax=ax1)\n",
    "#\n",
    "#x, _, feeds = next(batches(vae, labels, adj, adj.shape[0], adj.shape[0], None))\n",
    "#adj_pred = vae.predict_on_fed_batch(x, feeds=feeds)[1]\n",
    "#im2 = ax2.imshow(scipy.special.expit(adj_pred[0].mean(axis=0)))\n",
    "#im2.set_norm(im1.norm)\n",
    "#ax2.set_title('Predicted adjacency matrix')\n",
    "#plt.colorbar(im2, ax=ax2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './logs': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "rm -r ./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "seeds_per_batch = 5 #len(features)\n",
    "max_walk_length = 200\n",
    "p = 1\n",
    "q = 1\n",
    "neighbour_samples = 30\n",
    "\n",
    "steps_per_epoch = int(np.ceil(len(labels) / seeds_per_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute the CSGraph\n",
    "_ = graph.get_csgraph(adj, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "cProfile.run(\n",
    "'''for batch in batching.batches(vae, adj, labels, target_func,\n",
    "                              seeds_per_batch, max_walk_length,\n",
    "                              p=p, q=q, neighbour_samples=neighbour_samples):\n",
    "    i += 1\n",
    "    if i >= steps_per_epoch:\n",
    "        break''',\n",
    "             'gcn-ae-blogcatalog_batching-n_epochs={}-seeds_per_batch={}-max_walk_length={}-p={}-q={}-neighbour_samples={}-crop={}.profile'\n",
    "             .format(n_epochs, seeds_per_batch, max_walk_length, p, q, neighbour_samples, crop)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, the cell above complains with \"UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\". See these for more details:\n",
    "* https://stackoverflow.com/questions/35892412/tensorflow-dense-gradient-explanation#35896823\n",
    "* https://stackoverflow.com/questions/39111373/tensorflow-chaining-tf-gather-produces-indexedslices-warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After training:** $\\xi$ averages and distributions for each community, real and predicted adjacency matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ξ_distribution((g, l, k), q_model, adj, features, batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted adjacency matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 4))\n",
    "\n",
    "im1 = ax1.imshow(nx.adjacency_matrix(g).todense())\n",
    "ax1.set_title('Real adjacency matrix')\n",
    "plt.colorbar(im1, ax=ax1)\n",
    "\n",
    "x, _, feeds = next(batches(vae, features, adj, adj.shape[0], adj.shape[0], None))\n",
    "adj_pred = vae.predict_on_fed_batch(x, feeds=feeds)[1]\n",
    "im2 = ax2.imshow(scipy.special.expit(adj_pred[0].mean(axis=0)))\n",
    "im2.set_norm(im1.norm)\n",
    "ax2.set_title('Predicted adjacency matrix')\n",
    "plt.colorbar(im2, ax=ax2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.random.binomial(1, scipy.special.expit(adj_pred[0].mean(axis=0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in q_model.layers:\n",
    "    if hasattr(layer, 'kernel'):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 4))#, sharey=True)\n",
    "        im1 = ax1.imshow(K.eval(layer.kernel).T)\n",
    "        ax1.set_title('{} kernel'.format(layer.name))\n",
    "        plt.colorbar(im1, ax=ax1)\n",
    "    if hasattr(layer, 'bias') and layer.bias is not None:\n",
    "        im2 = ax2.imshow(K.eval(K.expand_dims(layer.bias, -1)))\n",
    "        ax2.set_title('{} bias'.format(layer.name))\n",
    "        plt.colorbar(im2, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in p_model.layers:\n",
    "    if hasattr(layer, 'kernel'):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 4))#, sharey=True)\n",
    "        im1 = ax1.imshow(K.eval(layer.kernel).T)\n",
    "        ax1.set_title('{} kernel'.format(layer.name))\n",
    "        plt.colorbar(im1, ax=ax1)\n",
    "    if hasattr(layer, 'bias') and layer.bias is not None:\n",
    "        im2 = ax2.imshow(K.eval(K.expand_dims(layer.bias, -1)))\n",
    "        ax2.set_title('{} bias'.format(layer.name))\n",
    "        plt.colorbar(im2, ax=ax2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
